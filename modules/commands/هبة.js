const { Configuration, OpenAIApi } = require('openai');

// Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø±Ùƒ Ù„ÙŠÙ‚Ø±Ø£ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Render Environment Variables
const configuration = new Configuration({
  apiKey: process.env.OPENAI_KEY, // Ù‚Ù…Ù†Ø§ Ø¨Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙˆÙƒÙ† ÙˆÙˆØ¶Ø¹Ù†Ø§ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù†Ù‡
});
const openai = new OpenAIApi(configuration);

// ÙƒØ§Ø¦Ù† Ù„Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ§Ù‹
if (!global.heba_chat_memory) {
  global.heba_chat_memory = new Map();
}

module.exports.config = {
  name: "Ù‡Ø¨Ø©",
  version: "3.1.0",
  hasPermssion: 0,
  credits: "Ayman",
  description: "Ø°ÙƒØ§Ø¡ Ù‡Ø¨Ø© Ø§Ù„Ù…Ø·ÙˆØ± Ù…Ø¹ Ù…ÙŠØ²Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ù†Ø³Ø®Ø© Ø¢Ù…Ù†Ø©)",
  commandCategory: "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
  usages: "[Ø³Ø¤Ø§Ù„Ùƒ]",
  cooldowns: 5
};

module.exports.run = async function({ api, event, args }) {
  const { threadID, messageID, senderID } = event;
  const prompt = args.join(" ");

  if (!prompt) {
    return api.sendMessage("â•­â”€â”€â”€â”€ â€¢ ğ‘¯ğ‘¬ğ‘©ğ‘¨ â€¢ â”€â”€â”€â”€â•®\nâœ¨ Ù†Ø¹Ù…! Ø£Ù†Ø§ Ø£ØªØ°ÙƒØ±ÙƒØŒ Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø³Ø¤Ø§Ù„ Ø¢Ø®Ø±ØŸ\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯", threadID, messageID);
  }

  // 1. Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ø°Ø§ÙƒØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©
  if (!global.heba_chat_memory.has(senderID)) {
    global.heba_chat_memory.set(senderID, [
      { role: "system", content: "Ø£Ù†ØªÙ 'Ù‡Ø¨Ø©'ØŒ Ø¨ÙˆØª Ø°ÙƒÙŠ Ø¨Ù„Ù…Ø³Ø© Ø£Ù†Ø«ÙˆÙŠØ© Ù„Ø·ÙŠÙØ©ØŒ ØªØªØ­Ø¯Ø«ÙŠÙ† Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø³Ø§Ø¹Ø¯ ÙˆÙˆØ¯ÙˆØ¯ Ø¬Ø¯Ø§Ù‹." }
    ]);
  }

  let userMemory = global.heba_chat_memory.get(senderID);
  userMemory.push({ role: "user", content: prompt });

  if (userMemory.length > 10) userMemory.shift();

  api.setMessageReaction("âŒ›", messageID, () => {}, true);
  
  api.sendMessage("â•­â”€â”€â”€â”€ â€¢ ğ‘¯ğ‘¬ğ‘©ğ‘¨ â€¢ â”€â”€â”€â”€â•®\nğŸ§  Ø¬Ø§Ø±ÙŠ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø°Ø§ÙƒØ±ØªÙŠ ÙˆØ§Ù„Ø±Ø¯...\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯", threadID, async (err, info) => {
    try {
      // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ÙØªØ§Ø­ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ù‚Ø¨Ù„ Ø§Ù„Ø·Ù„Ø¨
      if (!process.env.OPENAI_KEY) {
        throw new Error("OPENAI_KEY_MISSING");
      }

      const response = await openai.createChatCompletion({
        model: "gpt-3.5-turbo",
        messages: userMemory,
        max_tokens: 800,
        temperature: 0.7
      });

      const reply = response.data.choices[0].message.content.trim();
      userMemory.push({ role: "assistant", content: reply });
      global.heba_chat_memory.set(senderID, userMemory);

      api.setMessageReaction("âœ…", messageID, () => {}, true);
      
      return api.editMessage(
        `â•­â”€â”€â”€â”€ â€¢ ğ‘¯ğ‘¬ğ‘©ğ‘¨ â€¢ â”€â”€â”€â”€â•®\n\nğŸ¤– Ù‡Ø¨Ø©:\n${reply}\n\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯`,
        info.messageID
      );

    } catch (error) {
      console.error("Memory Chat Error:", error);
      api.setMessageReaction("âŒ", messageID, () => {}, true);
      
      let errorMsg = "âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.";
      if (error.message === "OPENAI_KEY_MISSING") {
        errorMsg = "âŒ Ø®Ø·Ø£: Ù…ÙØªØ§Ø­ OPENAI_KEY ØºÙŠØ± Ù…Ø¶Ø§Ù ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Render!";
      }

      return api.editMessage(`â•­â”€â”€â”€â”€ â€¢ ğ‘¯ğ‘¬ğ‘©ğ‘¨ â€¢ â”€â”€â”€â”€â•®\n${errorMsg}\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯`, info.messageID);
    }
  }, messageID);
};
