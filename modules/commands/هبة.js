const { Configuration, OpenAIApi } = require('openai');

// Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø±Ùƒ
const configuration = new Configuration({
  apiKey: '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',
});
const openai = new OpenAIApi(configuration);

// ÙƒØ§Ø¦Ù† Ù„Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ§Ù‹ (Ø³ÙˆÙ ÙŠØªØµÙØ± Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª)
// Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª Ø­ÙØ¸Ø§Ù‹ Ø¯Ø§Ø¦Ù…ÙŠØ§Ù‹ ÙŠÙ…ÙƒÙ† Ø±Ø¨Ø·Ù‡ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª sqlite Ù„Ø§Ø­Ù‚Ø§Ù‹
if (!global.heba_chat_memory) {
  global.heba_chat_memory = new Map();
}

module.exports.config = {
  name: "Ù‡Ø¨Ø©",
  version: "3.0.0",
  hasPermssion: 0,
  credits: "Ayman",
  description: "Ø°ÙƒØ§Ø¡ Ù‡Ø¨Ø© Ø§Ù„Ù…Ø·ÙˆØ± Ù…Ø¹ Ù…ÙŠØ²Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©",
  commandCategory: "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
  usages: "[Ø³Ø¤Ø§Ù„Ùƒ]",
  cooldowns: 5
};

module.exports.run = async function({ api, event, args }) {
  const { threadID, messageID, senderID } = event;
  const prompt = args.join(" ");

  if (!prompt) {
    return api.sendMessage("â•­â”€â”€â”€â”€ â€¢ ğ‘¯ğ‘¬ğ‘©ğ‘¨ â€¢ â”€â”€â”€â”€â•®\nâœ¨ Ù†Ø¹Ù…! Ø£Ù†Ø§ Ø£ØªØ°ÙƒØ±ÙƒØŒ Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø³Ø¤Ø§Ù„ Ø¢Ø®Ø±ØŸ\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯", threadID, messageID);
  }

  // 1. Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ø°Ø§ÙƒØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©
  if (!global.heba_chat_memory.has(senderID)) {
    global.heba_chat_memory.set(senderID, [
      { role: "system", content: "Ø£Ù†ØªÙ 'Ù‡Ø¨Ø©'ØŒ Ø¨ÙˆØª Ø°ÙƒÙŠ Ø¨Ù„Ù…Ø³Ø© Ø£Ù†Ø«ÙˆÙŠØ© Ù„Ø·ÙŠÙØ©ØŒ ØªØªØ­Ø¯Ø«ÙŠÙ† Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø³Ø§Ø¹Ø¯ ÙˆÙˆØ¯ÙˆØ¯ Ø¬Ø¯Ø§Ù‹." }
    ]);
  }

  let userMemory = global.heba_chat_memory.get(senderID);

  // Ø¥Ø¶Ø§ÙØ© Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ø°Ø§ÙƒØ±Ø©
  userMemory.push({ role: "user", content: prompt });

  // ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø¢Ø®Ø± 10 Ø±Ø³Ø§Ø¦Ù„ ÙÙ‚Ø· Ù„Ø¹Ø¯Ù… Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„ØªÙˆÙƒÙ†Ø²)
  if (userMemory.length > 10) userMemory.shift();

  api.setMessageReaction("âŒ›", messageID, () => {}, true);
  
  api.sendMessage("â•­â”€â”€â”€â”€ â€¢ ğ‘¯ğ‘¬ğ‘©ğ‘¨ â€¢ â”€â”€â”€â”€â•®\nğŸ§  Ø¬Ø§Ø±ÙŠ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø°Ø§ÙƒØ±ØªÙŠ ÙˆØ§Ù„Ø±Ø¯...\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯", threadID, async (err, info) => {
    try {
      // 2. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙƒØ§Ù…Ù„Ø© (Ø§Ù„Ø°Ø§ÙƒØ±Ø© + Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯)
      const response = await openai.createChatCompletion({
        model: "gpt-3.5-turbo",
        messages: userMemory,
        max_tokens: 800,
        temperature: 0.7
      });

      const reply = response.data.choices[0].message.content.trim();

      // 3. Ø¥Ø¶Ø§ÙØ© Ø±Ø¯ Ø§Ù„Ø¨ÙˆØª Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ù„ÙƒÙŠ ÙŠØªØ°ÙƒØ±Ù‡ ÙÙŠ Ø§Ù„Ù…Ø±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
      userMemory.push({ role: "assistant", content: reply });
      global.heba_chat_memory.set(senderID, userMemory);

      api.setMessageReaction("âœ…", messageID, () => {}, true);
      
      return api.editMessage(
        `â•­â”€â”€â”€â”€ â€¢ ğ‘¯ğ‘¬ğ‘©ğ‘¨ â€¢ â”€â”€â”€â”€â•®\n\nğŸ¤– Ù‡Ø¨Ø©:\n${reply}\n\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯`,
        info.messageID
      );

    } catch (error) {
      console.error("Memory Chat Error:", error);
      api.setMessageReaction("âŒ", messageID, () => {}, true);
      return api.editMessage("â•­â”€â”€â”€â”€ â€¢ ğ‘¯ğ‘¬ğ‘©ğ‘¨ â€¢ â”€â”€â”€â”€â•®\nâŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø°Ø§ÙƒØ±ØªÙŠ Ù…Ù…ØªÙ„Ø¦Ø© Ø£Ùˆ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„.\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯", info.messageID);
    }
  }, messageID);
};
